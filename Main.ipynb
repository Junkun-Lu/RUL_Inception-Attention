{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Experiment.Experiment import Exp_Inception_Attention\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "    \n",
    "    \n",
    "args = dotdict()\n",
    "\n",
    "\"\"\"\n",
    "dataset_name: choose the dataset we used now\n",
    "\n",
    "MAXLIFE_CMAOPSS: the knee point of RUL in each engine's RUL --- for CMAPSS\n",
    "\n",
    "n_heads_full: the head num of FullAttention, used for ablation study\n",
    "n_heads_log: the head num of LogSparseAttention\n",
    "n_heads_local: the head num of LocalAttention\n",
    "n_heads_prob: the head num of ProbSparseAttention\n",
    "n_heads_FFT: the head num of FFT\n",
    "n_heads_auto: the head num of AutoCorrelation\n",
    "\n",
    "moving_avg: the kernel_size for decomposition block\n",
    "enc_layer_num : the number of layers in Encoder\n",
    "predictor_type: choose which Predictor used\n",
    "\n",
    "learning_rate_patience: learning rate change after learning_rate_patience's epoch\n",
    "learning_rate_factor: the percentage of learning rate change\n",
    "arly_stop_patience: the time of training stop, when vali loss always bigger\n",
    "\n",
    "enc_pred_loss: the loss function we choosed\n",
    "sigma_faktor: The larger the value, the smaller the simga and the narrower the distribution of weights\n",
    "anteil: The larger the value, the larger the subsequent distribution\n",
    "smooth_loss: use the smooth_loss or not\n",
    "\"\"\"\n",
    "\n",
    "# 1. load data parameter - common\n",
    "args.dataset_name   = \"CMAPSS\"   # CMAPSS/FEMTO/XJTU\n",
    "args.input_length   = 32\n",
    "args.validation     = 0.1\n",
    "args.batch_size     = 32\n",
    "\n",
    "# 1.1. load data parameter - CMAPSS\n",
    "args.data_path_CMAPSS       = \"D:/study/Master-Thesis/数据集-RUL/CMaps/\"\n",
    "args.Data_id_CMAPSS         = \"FD001\"\n",
    "args.MAXLIFE_CMAPSS         = 120\n",
    "args.difference_CMAPSS      = False\n",
    "args.normalization_CMAPSS   = \"minmax\"\n",
    "\n",
    "# 1.2. load data parameter - FEMTO\n",
    "args.pre_process_type_FEMTO         = \"tsfresh\"   # \"tsfresh\"/\"STFT\"/\"Vibration\"\n",
    "args.train_root_dir_FEMTO           = \"D:/study/Master-Thesis/数据集-RUL/Pronostia Bearing Dataset/ieee-phm-2012-data-challenge-dataset-master/Learning_set\"\n",
    "args.train_bearing_data_set_FEMTO   = [\"Bearing3_1\", \"Bearing3_2\"]\n",
    "args.test_root_dir_FEMTO            = \"D:/study/Master-Thesis/数据集-RUL/Pronostia Bearing Dataset/ieee-phm-2012-data-challenge-dataset-master/Test_set\" \n",
    "args.test_bearing_data_set_FEMTO    = [\"Bearing3_3\"]\n",
    "args.STFT_window_len_FEMTO          = 80\n",
    "args.STFT_overlap_num_FEMTO         = 10\n",
    "\n",
    "# 1.3. load data parameter - XJTU\n",
    "args.pre_process_type_XJTU          = \"vibration\"\n",
    "args.root_dir_XJTU                  = \"D:/study/Master-Thesis/数据集-RUL/XJTU-SY_Bearing_Datasets/35Hz12kN\"\n",
    "args.train_bearing_data_set_XJTU    = [\"Bearing1_2\", \"Bearing1_3\", \"Bearing1_4\", \"Bearing1_5\"]\n",
    "args.test_bearing_data_set_XJTU     = [\"Bearing1_1\"]\n",
    "args.STFT_window_len_XJTU           = 256\n",
    "args.STFT_overlap_num_XJTU          = 32\n",
    "\n",
    "# 2. model parameter -common\n",
    "args.d_model    = 240       # n*d_k/d_v*multiple\n",
    "args.dropout    = 0.1\n",
    "\n",
    "# 2.1. Preprocess Layer parameter\n",
    "args.preprocess_type        = \"FC\"      # \"FC\"/\"STFT\"/\"Conv\"\n",
    "args.preprocess_layer_num   = 3\n",
    "args.preprocess_filter_num  = 3         # 等于d_model中的n\n",
    "args.preprocess_kernel_size = 13        \n",
    "args.preprocess_stride      = 2\n",
    "\n",
    "# 2.2. Encoder parameter\n",
    "args.attention_layer_types  = [\"Local\", \"Log\", \"Prob\"]    # [\"Full\", \"Local\", \"Log\", \"Prob\", \"Auto\", \"FFT\"]\n",
    "args.n_heads_full           = 0\n",
    "args.n_heads_local          = 2\n",
    "args.n_heads_log            = 2\n",
    "args.n_heads_prob           = 2\n",
    "args.n_heads_auto           = 0\n",
    "args.n_heads_fft            = 0\n",
    "args.d_keys                 = None\n",
    "args.d_values               = None\n",
    "args.d_ff                   = None\n",
    "args.activation             = \"relu\"\n",
    "args.forward_kernel_size    = 1\n",
    "args.value_kernel_size      = 1\n",
    "args.causal_kernel_size     = 3\n",
    "args.output_attention       = True\n",
    "args.auto_moving_avg        = 9\n",
    "args.enc_layer_num          = 1  \n",
    "\n",
    "# 2.3. Predictor parameter\n",
    "args.predictor_type     = \"hybrid\"\n",
    "\n",
    "\n",
    "# 3. training parameter\n",
    "args.train_epochs   = 200\n",
    "args.use_gpu        = True  # True if torch.cuda.is_available() else False\n",
    "args.gpu            = 0\n",
    "\n",
    "# 3.1. optimizer parameter\n",
    "args.optimizer              = \"Adam\"\n",
    "args.learning_rate          = 0.001\n",
    "args.learning_rate_patience = 10\n",
    "args.learning_rate_factor   = 0.3\n",
    "args.early_stop_patience    = 60\n",
    "\n",
    "# 3.2. loss parameter\n",
    "args.sigma_faktor   = 15   # 越大 simga越小  权重分布就越窄\n",
    "args.anteil         = 40   # 越大 比重反差就越大，后面的分布也就越大\n",
    "args.enc_pred_loss  = \"WeightMSE\"  # \"MSE\"\n",
    "args.weight_type    = \"gaussian\"\n",
    "args.smooth_loss    = \"smooth_mse\"  # None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = Exp_Inception_Attention(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"FD001\"\n",
    "exp.train(save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88279d2366fe020547cde40dd65aa0e3aa662a6ec1f3ca12d88834876c85e1a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
